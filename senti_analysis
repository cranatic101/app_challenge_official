from operator import itemgetter
import math
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
from nltk.tokenize import *
stop_words = set(stopwords.words('english'))
sia = SentimentIntensityAnalyzer()
'''
def senti_analyze(text, sentiment=None): # both strings
    sia = SentimentIntensityAnalyzer()
    if sentiment is not None:
        return sia.polarity_scores(text)[sentiment]*100
    else:
        dic=sia.polarity_scores(text)
        sentiments=[]
        for i in tuple([dic[i] for i in dic]):
            sentiments.append(i*100)
        return sentiments
'''              

#def keyword_extractor(text):
text="Heartbreaking to see the number of colleagues stepping down because of the daily stream of online abuse. No one, in any job, should be abused this way. Surely we as a society can be better than this"
total_sentences = nltk.tokenize.sent_tokenize(text)
total_sent_len = len(total_sentences)
total_words = text.split()
total_word_length = len(total_words)
tf_score = {}
for each_word in total_words:
    each_word = each_word.replace('.','')
    if each_word not in stop_words:
        if each_word in tf_score:
            tf_score[each_word] += 1
        else:
            tf_score[each_word] = 1

# Dividing by total_word_length for each dictionary element
tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())


def check_sent(word, sentences): 
    final = [all([w in x for w in word]) for x in sentences] 
    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]
    return int(len(sent_len))

idf_score = {}
for each_word in total_words:
    each_word = each_word.replace('.','')
    if each_word not in stop_words:
        if each_word in idf_score:
            idf_score[each_word] = check_sent(each_word, total_sentences)
        else:
            idf_score[each_word] = 1

# Performing a log and divide
idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())

tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}


def get_top_n(dict_elem, n):
    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) 
    return result

print(get_top_n(tf_idf_score, 5))